[
    {
        "epoch": 0.08292542470486611,
        "grad_norm": 0.48470112681388855,
        "learning_rate": 9.893048128342246e-05,
        "loss": 3.0002,
        "mean_token_accuracy": 0.3995637027417413,
        "num_tokens": 174014.0,
        "step": 72
    },
    {
        "epoch": 0.16585084940973222,
        "grad_norm": 0.5250518918037415,
        "learning_rate": 9.46524064171123e-05,
        "loss": 2.5045,
        "mean_token_accuracy": 0.4724622813777791,
        "num_tokens": 341763.0,
        "step": 144
    },
    {
        "epoch": 0.24877627411459832,
        "grad_norm": 0.9178979992866516,
        "learning_rate": 9.037433155080214e-05,
        "loss": 2.4375,
        "mean_token_accuracy": 0.48064843223740655,
        "num_tokens": 517256.0,
        "step": 216
    },
    {
        "epoch": 0.33170169881946443,
        "grad_norm": 0.5032238960266113,
        "learning_rate": 8.609625668449198e-05,
        "loss": 2.4276,
        "mean_token_accuracy": 0.4821707042865455,
        "num_tokens": 689698.0,
        "step": 288
    },
    {
        "epoch": 0.41462712352433057,
        "grad_norm": 0.6839348673820496,
        "learning_rate": 8.181818181818183e-05,
        "loss": 2.3772,
        "mean_token_accuracy": 0.4873814437434905,
        "num_tokens": 858552.0,
        "step": 360
    },
    {
        "epoch": 0.49755254822919665,
        "grad_norm": 0.5442507266998291,
        "learning_rate": 7.754010695187165e-05,
        "loss": 2.3805,
        "mean_token_accuracy": 0.4890380134909517,
        "num_tokens": 1026814.0,
        "step": 432
    },
    {
        "epoch": 0.5804779729340628,
        "grad_norm": 0.6486577987670898,
        "learning_rate": 7.326203208556151e-05,
        "loss": 2.3655,
        "mean_token_accuracy": 0.49294737591925597,
        "num_tokens": 1200354.0,
        "step": 504
    },
    {
        "epoch": 0.6634033976389289,
        "grad_norm": 0.8375715613365173,
        "learning_rate": 6.898395721925133e-05,
        "loss": 2.3365,
        "mean_token_accuracy": 0.4957274659019377,
        "num_tokens": 1376745.0,
        "step": 576
    },
    {
        "epoch": 0.7463288223437949,
        "grad_norm": 0.6675151586532593,
        "learning_rate": 6.470588235294118e-05,
        "loss": 2.3146,
        "mean_token_accuracy": 0.4991514534792966,
        "num_tokens": 1549637.0,
        "step": 648
    },
    {
        "epoch": 0.8292542470486611,
        "grad_norm": 0.6026356816291809,
        "learning_rate": 6.0427807486631016e-05,
        "loss": 2.3254,
        "mean_token_accuracy": 0.49836023586491746,
        "num_tokens": 1722805.0,
        "step": 720
    },
    {
        "epoch": 0.9121796717535272,
        "grad_norm": 0.6705484986305237,
        "learning_rate": 5.614973262032086e-05,
        "loss": 2.313,
        "mean_token_accuracy": 0.49805427834184635,
        "num_tokens": 1902209.0,
        "step": 792
    },
    {
        "epoch": 0.9951050964583933,
        "grad_norm": 0.80318683385849,
        "learning_rate": 5.1871657754010694e-05,
        "loss": 2.3323,
        "mean_token_accuracy": 0.49597615184676314,
        "num_tokens": 2075417.0,
        "step": 864
    },
    {
        "epoch": 1.0771667146559172,
        "grad_norm": 0.7551620602607727,
        "learning_rate": 4.759358288770054e-05,
        "loss": 2.3005,
        "mean_token_accuracy": 0.5028578606613895,
        "num_tokens": 2240765.0,
        "step": 936
    },
    {
        "epoch": 1.1600921393607833,
        "grad_norm": 0.685917317867279,
        "learning_rate": 4.331550802139038e-05,
        "loss": 2.2832,
        "mean_token_accuracy": 0.5032251926863359,
        "num_tokens": 2414435.0,
        "step": 1008
    },
    {
        "epoch": 1.2430175640656493,
        "grad_norm": 0.6468517780303955,
        "learning_rate": 3.903743315508022e-05,
        "loss": 2.2708,
        "mean_token_accuracy": 0.5048581432654626,
        "num_tokens": 2589187.0,
        "step": 1080
    },
    {
        "epoch": 1.3259429887705154,
        "grad_norm": 0.8346549868583679,
        "learning_rate": 3.4759358288770055e-05,
        "loss": 2.2799,
        "mean_token_accuracy": 0.5027424996304843,
        "num_tokens": 2764764.0,
        "step": 1152
    },
    {
        "epoch": 1.4088684134753815,
        "grad_norm": 0.897178053855896,
        "learning_rate": 3.0481283422459894e-05,
        "loss": 2.2961,
        "mean_token_accuracy": 0.49969984735879636,
        "num_tokens": 2933877.0,
        "step": 1224
    },
    {
        "epoch": 1.4917938381802476,
        "grad_norm": 0.8272968530654907,
        "learning_rate": 2.6203208556149733e-05,
        "loss": 2.2656,
        "mean_token_accuracy": 0.503934231845455,
        "num_tokens": 3107223.0,
        "step": 1296
    },
    {
        "epoch": 1.5747192628851137,
        "grad_norm": 0.8563207387924194,
        "learning_rate": 2.192513368983957e-05,
        "loss": 2.2918,
        "mean_token_accuracy": 0.5000550805901488,
        "num_tokens": 3284232.0,
        "step": 1368
    },
    {
        "epoch": 1.65764468758998,
        "grad_norm": 0.8884132504463196,
        "learning_rate": 1.7647058823529414e-05,
        "loss": 2.2825,
        "mean_token_accuracy": 0.5018166642015179,
        "num_tokens": 3454854.0,
        "step": 1440
    },
    {
        "epoch": 1.7405701122948458,
        "grad_norm": 0.8978675007820129,
        "learning_rate": 1.3368983957219252e-05,
        "loss": 2.2682,
        "mean_token_accuracy": 0.5031732798864444,
        "num_tokens": 3628049.0,
        "step": 1512
    },
    {
        "epoch": 1.8234955369997121,
        "grad_norm": 0.7936128973960876,
        "learning_rate": 9.090909090909091e-06,
        "loss": 2.2545,
        "mean_token_accuracy": 0.5119394705527358,
        "num_tokens": 3802251.0,
        "step": 1584
    },
    {
        "epoch": 1.9064209617045782,
        "grad_norm": 0.8452836275100708,
        "learning_rate": 4.812834224598931e-06,
        "loss": 2.2767,
        "mean_token_accuracy": 0.5060462790748311,
        "num_tokens": 3977289.0,
        "step": 1656
    },
    {
        "epoch": 1.9893463864094443,
        "grad_norm": 0.612299919128418,
        "learning_rate": 5.347593582887701e-07,
        "loss": 2.258,
        "mean_token_accuracy": 0.5057252257958882,
        "num_tokens": 4147865.0,
        "step": 1728
    },
    {
        "train_runtime": 0.0136,
        "train_samples_per_second": 2036992.461,
        "train_steps_per_second": 127284.534,
        "total_flos": 1.3281424942301184e+17,
        "train_loss": 0.0,
        "epoch": 1.9985603224877626,
        "step": 1736
    }
]